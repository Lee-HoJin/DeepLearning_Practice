import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

class PCAGeometricDemo:
    def __init__(self):
        print("ğŸ¯ PCA Geometric Understanding")
        print("=" * 40)
    
    def create_2d_data(self):
        """2D ë°ì´í„° ìƒì„± (íƒ€ì›í˜• ë¶„í¬)"""
        np.random.seed(42)
        n_samples = 200
        
        # ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ë°ì´í„° ìƒì„±
        mean = [0, 0]
        cov = [[3, 1.5],    # x ë¶„ì‚°=3, ê³µë¶„ì‚°=1.5
               [1.5, 1]]    # y ë¶„ì‚°=1, ê³µë¶„ì‚°=1.5
        
        data = np.random.multivariate_normal(mean, cov, n_samples)
        return data
    
    def visualize_pca_process(self):
        """PCA ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°"""
        print("\nğŸ“Š PCA Geometric Interpretation")
        print("-" * 32)
        
        data = self.create_2d_data()
        
        # PCA ì ìš©
        pca = PCA(n_components=2)
        pca.fit(data)
        
        # ì£¼ì„±ë¶„ë“¤
        pc1 = pca.components_[0]  # ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ (ìµœëŒ€ ë¶„ì‚° ë°©í–¥)
        pc2 = pca.components_[1]  # ë‘ ë²ˆì§¸ ì£¼ì„±ë¶„ (PC1ì— ì§êµ)
        
        print(f"Data shape: {data.shape}")
        print(f"Data center: [{np.mean(data[:,0]):.3f}, {np.mean(data[:,1]):.3f}]")
        
        print(f"\nğŸ¯ Principal Components:")
        print(f"PC1 (1st component): [{pc1[0]:6.3f}, {pc1[1]:6.3f}]")
        print(f"PC1 magnitude: {np.linalg.norm(pc1):.6f} â† Unit vector!")
        print(f"PC2 (2nd component): [{pc2[0]:6.3f}, {pc2[1]:6.3f}]")
        print(f"PC2 magnitude: {np.linalg.norm(pc2):.6f} â† Unit vector!")
        
        # ì§êµì„± í™•ì¸
        orthogonal = np.dot(pc1, pc2)
        print(f"PC1 Â· PC2 (orthogonality): {orthogonal:.10f} â† Should be ~0")
        
        # ë¶„ì‚° ì •ë³´
        print(f"\nğŸ“ˆ Variance Information:")
        print(f"Explained variance: {pca.explained_variance_}")
        print(f"Explained variance ratio: {pca.explained_variance_ratio_}")
        print(f"Total variance explained: {sum(pca.explained_variance_ratio_):.6f}")
        
        # ë°ì´í„° ì¤‘ì‹¬
        center = np.mean(data, axis=0)
        
        # ì‹œê°í™”
        plt.figure(figsize=(12, 5))
        
        # ì›ë³¸ ë°ì´í„°ì™€ ì£¼ì„±ë¶„
        plt.subplot(1, 2, 1)
        plt.scatter(data[:, 0], data[:, 1], alpha=0.6, c='blue', s=20)
        plt.scatter(center[0], center[1], c='red', s=100, marker='x', linewidth=3)
        
        # ì£¼ì„±ë¶„ ë°©í–¥ í‘œì‹œ (í™”ì‚´í‘œ)
        scale = 3  # ì‹œê°í™”ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¼ë§
        plt.arrow(center[0], center[1], pc1[0]*scale, pc1[1]*scale, 
                  head_width=0.1, head_length=0.1, fc='red', ec='red', linewidth=2,
                  label=f'PC1 (explains {pca.explained_variance_ratio_[0]:.1%})')
        plt.arrow(center[0], center[1], pc2[0]*scale, pc2[1]*scale,
                  head_width=0.1, head_length=0.1, fc='green', ec='green', linewidth=2,
                  label=f'PC2 (explains {pca.explained_variance_ratio_[1]:.1%})')
        
        plt.title('Original Data with Principal Components')
        plt.xlabel('X1')
        plt.ylabel('X2')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.axis('equal')
        
        # 1ì°¨ì›ìœ¼ë¡œ íˆ¬ì˜ (PC1 ë°©í–¥ìœ¼ë¡œë§Œ)
        plt.subplot(1, 2, 2)
        
        # PC1 ë°©í–¥ìœ¼ë¡œ íˆ¬ì˜ëœ ì¢Œí‘œë“¤
        projected_1d = np.dot(data - center, pc1)  # ìŠ¤ì¹¼ë¼ ê°’ë“¤
        
        # 1D íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ ë¶„í¬ ë³´ê¸°
        plt.hist(projected_1d, bins=30, alpha=0.7, color='red', edgecolor='black')
        plt.title('Data Projected onto PC1 (2D â†’ 1D)')
        plt.xlabel('Projected coordinate on PC1')
        plt.ylabel('Frequency')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return data, pca, projected_1d
    
    def demonstrate_projection_math(self):
        """íˆ¬ì˜ ìˆ˜í•™ ìì„¸íˆ ì„¤ëª…"""
        print(f"\nğŸ§® Projection Mathematics")
        print("-" * 25)
        
        data = self.create_2d_data()
        pca = PCA(n_components=1)  # 1ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ
        projected = pca.fit_transform(data)
        
        pc1 = pca.components_[0]  # ì²« ë²ˆì§¸ ì£¼ì„±ë¶„
        center = np.mean(data, axis=0)
        
        print(f"Principal component (unit vector): {pc1}")
        print(f"Data center: {center}")
        
        # ëª‡ ê°œ ìƒ˜í”Œì˜ íˆ¬ì˜ ê³¼ì • ë³´ê¸°
        print(f"\nğŸ“ Manual Projection Examples:")
        for i in range(3):
            original_point = data[i]
            centered_point = original_point - center
            
            # ìˆ˜ë™ íˆ¬ì˜: (v Â· u) where u is unit vector
            manual_projection = np.dot(centered_point, pc1)
            sklearn_projection = projected[i, 0]
            
            print(f"\nSample {i+1}:")
            print(f"  Original point: [{original_point[0]:6.3f}, {original_point[1]:6.3f}]")
            print(f"  Centered point: [{centered_point[0]:6.3f}, {centered_point[1]:6.3f}]")
            print(f"  Manual projection: {manual_projection:6.3f}")
            print(f"  Sklearn projection: {sklearn_projection:6.3f}")
            print(f"  Match? {np.isclose(manual_projection, sklearn_projection)}")
    
    def compare_different_directions(self):
        """ë‹¤ë¥¸ ë°©í–¥ë“¤ê³¼ ë¶„ì‚° ë¹„êµ"""
        print(f"\nğŸ¯ Why PC1 is Optimal Direction")
        print("-" * 30)
        
        data = self.create_2d_data()
        center = np.mean(data, axis=0)
        centered_data = data - center
        
        # PCA ê²°ê³¼
        pca = PCA(n_components=1)
        pca.fit(data)
        optimal_direction = pca.components_[0]
        
        # ì—¬ëŸ¬ ë°©í–¥ë“¤ í…ŒìŠ¤íŠ¸
        angles = np.linspace(0, np.pi, 9)  # 0ë„ë¶€í„° 180ë„ê¹Œì§€
        directions = np.array([[np.cos(angle), np.sin(angle)] for angle in angles])
        
        variances = []
        for direction in directions:
            # ê° ë°©í–¥ìœ¼ë¡œ íˆ¬ì˜
            projections = np.dot(centered_data, direction)
            variance = np.var(projections)
            variances.append(variance)
        
        print(f"Optimal direction (PC1): [{optimal_direction[0]:6.3f}, {optimal_direction[1]:6.3f}]")
        print(f"Optimal variance: {pca.explained_variance_[0]:.6f}")
        
        print(f"\nTesting different directions:")
        for i, (angle, direction, variance) in enumerate(zip(angles, directions, variances)):
            angle_deg = np.degrees(angle)
            print(f"  {angle_deg:3.0f}Â°: direction=[{direction[0]:6.3f}, {direction[1]:6.3f}], "
                  f"variance={variance:6.3f}")
        
        max_variance_idx = np.argmax(variances)
        print(f"\nMaximum variance achieved at {np.degrees(angles[max_variance_idx]):3.0f}Â°")
        print(f"This matches our PC1 direction: "
              f"{np.allclose(directions[max_variance_idx], optimal_direction, atol=0.1)}")
    
    def normalization_deep_dive(self):
        """ì •ê·œí™”ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ë¶„ì„"""
        print(f"\nğŸ”¬ PCA Normalization Deep Dive")
        print("-" * 32)
        
        data = self.create_2d_data()
        pca = PCA(n_components=2)
        pca.fit(data)
        
        print("âœ… PCA Components are Unit Vectors:")
        for i, component in enumerate(pca.components_):
            magnitude = np.linalg.norm(component)
            print(f"  PC{i+1}: {component} â†’ ||PC{i+1}|| = {magnitude:.10f}")
        
        print(f"\nğŸ” What about the magnitude information?")
        print(f"Explained variance (eigenvalues): {pca.explained_variance_}")
        print(f"Standard deviations: {np.sqrt(pca.explained_variance_)}")
        
        # ì‹¤ì œ ê³ ìœ ë²¡í„° vs PCA components
        # ê³µë¶„ì‚° í–‰ë ¬ ì§ì ‘ ê³„ì‚°
        centered_data = data - np.mean(data, axis=0)
        cov_matrix = np.cov(centered_data.T)
        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
        
        # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        idx = np.argsort(eigenvalues)[::-1]
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]
        
        print(f"\nğŸ”¬ Manual Eigendecomposition:")
        print(f"Eigenvalues: {eigenvalues}")
        print(f"Eigenvectors (columns):")
        for i in range(eigenvectors.shape[1]):
            eigenvec = eigenvectors[:, i]
            print(f"  Eigenvector {i+1}: {eigenvec}")
            print(f"  Magnitude: {np.linalg.norm(eigenvec):.10f}")
        
        print(f"\nğŸ¯ Comparison:")
        print(f"PCA explained_variance vs Eigenvalues: "
              f"{np.allclose(pca.explained_variance_, eigenvalues)}")
        
        # ë°©í–¥ ë¹„êµ (ë¶€í˜¸ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        for i in range(2):
            pca_comp = pca.components_[i]
            eigenvec = eigenvectors[:, i]
            
            # ë¶€í˜¸ ë³´ì • (ì²« ë²ˆì§¸ ì„±ë¶„ì´ ì–‘ìˆ˜ê°€ ë˜ë„ë¡)
            if pca_comp[0] < 0:
                pca_comp = -pca_comp
            if eigenvec[0] < 0:
                eigenvec = -eigenvec
                
            match = np.allclose(pca_comp, eigenvec)
            print(f"PC{i+1} vs Eigenvector{i+1}: {match}")
    
    def answer_user_questions(self):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€"""
        print(f"\n" + "="*50)
        print("ğŸ¯ ANSWERS TO YOUR QUESTIONS")
        print("="*50)
        
        print(f"\n1ï¸âƒ£ 2D â†’ 1D ì¶•ì†Œì˜ geometric ì˜ë¯¸:")
        print(f"   âœ… YES! ë°ì´í„° ë¶„í¬ë¥¼ ê°€ì¥ ì˜ í‘œí˜„í•˜ëŠ” í•˜ë‚˜ì˜ ë°©í–¥(ì§ì„ )ì„ ì°¾ëŠ” ê²ƒ")
        print(f"   ğŸ“ ì´ ë°©í–¥ìœ¼ë¡œ íˆ¬ì˜í–ˆì„ ë•Œ ë¶„ì‚°ì´ ìµœëŒ€ê°€ ë˜ëŠ” ë°©í–¥")
        print(f"   ğŸ­ íƒ€ì›í˜• ë°ì´í„°ì—ì„œ ì¥ì¶• ë°©í–¥ì„ ì°¾ëŠ” ê²ƒê³¼ ê°™ìŒ")
        
        print(f"\n2ï¸âƒ£ PCA ì£¼ì„±ë¶„ì´ ì´ë¯¸ normalizedì¸ê°€:")
        print(f"   âœ… YES! ëª¨ë“  ì£¼ì„±ë¶„(principal components)ì€ ë‹¨ìœ„ë²¡í„°")
        print(f"   ğŸ“ ||PC_i|| = 1.0 (ì •í™•íˆ)")
        print(f"   ğŸ” ë°©í–¥ë§Œ ë‚˜íƒ€ë‚´ê³ , í¬ê¸° ì •ë³´ëŠ” explained_variance_ì— ë”°ë¡œ ì €ì¥")
        print(f"   ğŸ’¡ ë”°ë¼ì„œ ì´ë¯¸ ì •ê·œí™”(normalized)ë˜ì–´ ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ")
    
    def run_all_demos(self):
        """ëª¨ë“  ë°ëª¨ ì‹¤í–‰"""
        data, pca, projected = self.visualize_pca_process()
        self.demonstrate_projection_math()
        self.compare_different_directions()
        self.normalization_deep_dive()
        self.answer_user_questions()
        
        return data, pca, projected

# ì‹¤í–‰
if __name__ == "__main__":
    demo = PCAGeometricDemo()
    results = demo.run_all_demos()